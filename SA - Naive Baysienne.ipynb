{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "nltk.download('stopwords')\n",
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('E:/UCL/BIR22/Sentiment analysis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importation et preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Dataset d'entrainement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1. Creation des datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importation\n",
    "\n",
    "Data_entrainement = pd.read_csv(\"./training.1600000.processed.noemoticon.csv\", header = None, encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Tweet_ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Query_username</th>\n",
       "      <th>Username</th>\n",
       "      <th>Tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601966</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>AmandaMarie1028</td>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601969</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>TheWDBoards</td>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601991</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>bpbabe</td>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>4</td>\n",
       "      <td>2193602064</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>tinydiamondz</td>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>4</td>\n",
       "      <td>2193602129</td>\n",
       "      <td>Tue Jun 16 08:40:50 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>RyanTrevMorris</td>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Polarity    Tweet_ID                          Date Query_username  \\\n",
       "0               0  1467810369  Mon Apr 06 22:19:45 PDT 2009       NO_QUERY   \n",
       "1               0  1467810672  Mon Apr 06 22:19:49 PDT 2009       NO_QUERY   \n",
       "2               0  1467810917  Mon Apr 06 22:19:53 PDT 2009       NO_QUERY   \n",
       "3               0  1467811184  Mon Apr 06 22:19:57 PDT 2009       NO_QUERY   \n",
       "4               0  1467811193  Mon Apr 06 22:19:57 PDT 2009       NO_QUERY   \n",
       "...           ...         ...                           ...            ...   \n",
       "1599995         4  2193601966  Tue Jun 16 08:40:49 PDT 2009       NO_QUERY   \n",
       "1599996         4  2193601969  Tue Jun 16 08:40:49 PDT 2009       NO_QUERY   \n",
       "1599997         4  2193601991  Tue Jun 16 08:40:49 PDT 2009       NO_QUERY   \n",
       "1599998         4  2193602064  Tue Jun 16 08:40:49 PDT 2009       NO_QUERY   \n",
       "1599999         4  2193602129  Tue Jun 16 08:40:50 PDT 2009       NO_QUERY   \n",
       "\n",
       "                Username                                         Tweet_text  \n",
       "0        _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1          scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2               mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3                ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4                 Karoli  @nationwideclass no, it's not behaving at all....  \n",
       "...                  ...                                                ...  \n",
       "1599995  AmandaMarie1028  Just woke up. Having no school is the best fee...  \n",
       "1599996      TheWDBoards  TheWDB.com - Very cool to hear old Walt interv...  \n",
       "1599997           bpbabe  Are you ready for your MoJo Makeover? Ask me f...  \n",
       "1599998     tinydiamondz  Happy 38th Birthday to my boo of alll time!!! ...  \n",
       "1599999   RyanTrevMorris  happy #charitytuesday @theNSPCC @SparksCharity...  \n",
       "\n",
       "[1600000 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#On donne des noms aux colonnes\n",
    "\n",
    "Data_entrainement.columns = ['Polarity', 'Tweet_ID','Date','Query_username','Username','Tweet_text']\n",
    "Data_entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4]\n"
     ]
    }
   ],
   "source": [
    "#montre qu'il n'y a bien que 2 polarité dans le tableau\n",
    "a = []\n",
    "for i in Data[0]:\n",
    "    if i not in a:\n",
    "        a.append(i)\n",
    "print(a)\n",
    "#0 = negative, 4 = positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Tweet_ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Query_username</th>\n",
       "      <th>Username</th>\n",
       "      <th>Tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>908271</th>\n",
       "      <td>4</td>\n",
       "      <td>1696135115</td>\n",
       "      <td>Mon May 04 07:40:55 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mikesawriter</td>\n",
       "      <td>@MmmBaileys @carli_chick Hello</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895174</th>\n",
       "      <td>4</td>\n",
       "      <td>1692567464</td>\n",
       "      <td>Sun May 03 20:16:43 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>CodyOW</td>\n",
       "      <td>@DSCarey tell me that didn't make your day hap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551520</th>\n",
       "      <td>4</td>\n",
       "      <td>2184090411</td>\n",
       "      <td>Mon Jun 15 15:24:29 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>chrisyoungken</td>\n",
       "      <td>watching big brother. LOL @ what they did to s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1392222</th>\n",
       "      <td>4</td>\n",
       "      <td>2053389604</td>\n",
       "      <td>Sat Jun 06 04:22:52 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>lorna_hughes</td>\n",
       "      <td>@cromwellswirral sounds good, will make sure I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240101</th>\n",
       "      <td>4</td>\n",
       "      <td>1993705920</td>\n",
       "      <td>Mon Jun 01 10:48:13 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>VisitBooneNC</td>\n",
       "      <td>@redmantw I love the Moses Cone Manor   It's g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Polarity    Tweet_ID                          Date Query_username  \\\n",
       "908271          4  1696135115  Mon May 04 07:40:55 PDT 2009       NO_QUERY   \n",
       "895174          4  1692567464  Sun May 03 20:16:43 PDT 2009       NO_QUERY   \n",
       "1551520         4  2184090411  Mon Jun 15 15:24:29 PDT 2009       NO_QUERY   \n",
       "1392222         4  2053389604  Sat Jun 06 04:22:52 PDT 2009       NO_QUERY   \n",
       "1240101         4  1993705920  Mon Jun 01 10:48:13 PDT 2009       NO_QUERY   \n",
       "\n",
       "              Username                                         Tweet_text  \n",
       "908271    mikesawriter                    @MmmBaileys @carli_chick Hello   \n",
       "895174          CodyOW  @DSCarey tell me that didn't make your day hap...  \n",
       "1551520  chrisyoungken  watching big brother. LOL @ what they did to s...  \n",
       "1392222   lorna_hughes  @cromwellswirral sounds good, will make sure I...  \n",
       "1240101   VisitBooneNC  @redmantw I love the Moses Cone Manor   It's g...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Selection de tweets\n",
    "\n",
    "Datapos = Data_entrainement[Data_entrainement['Polarity']==4]\n",
    "Dataneg = Data_entrainement[Data_entrainement['Polarity']==0]\n",
    "\n",
    "Data_sub = pd.concat([Datapos.sample(5000),Dataneg.sample(5000)],axis=0)\n",
    "Data_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800000 800000\n"
     ]
    }
   ],
   "source": [
    "#pour vérifier que pos et neg ont la même longueur\n",
    "print(len(Datapos),len(Dataneg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepro(text,i):\n",
    "    clean=text[i].astype(str).str.replace(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \")\n",
    "    lowercase=clean.str.lower()\n",
    "    words=lowercase.apply(word_tokenize)\n",
    "    stop_words = stopwords.words('english') \n",
    "    filtered_words = words.apply(lambda x:[word for word in x if word not in stop_words])\n",
    "    porter = PorterStemmer()\n",
    "    text['Tweet_clean']=filtered_words.apply(lambda x:[porter.stem(word) for word in x])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_sub_clean = prepro(Data_sub,'Tweet_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset l'index\n",
    "\n",
    "Data_sub_clean.reset_index(inplace=True)\n",
    "del Data_sub_clean['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Tweet_ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Query_username</th>\n",
       "      <th>Username</th>\n",
       "      <th>Tweet_text</th>\n",
       "      <th>Tweet_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1696135115</td>\n",
       "      <td>Mon May 04 07:40:55 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mikesawriter</td>\n",
       "      <td>@MmmBaileys @carli_chick Hello</td>\n",
       "      <td>[chick, hello]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1692567464</td>\n",
       "      <td>Sun May 03 20:16:43 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>CodyOW</td>\n",
       "      <td>@DSCarey tell me that didn't make your day hap...</td>\n",
       "      <td>[tell, make, day, happier, though, lt, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2184090411</td>\n",
       "      <td>Mon Jun 15 15:24:29 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>chrisyoungken</td>\n",
       "      <td>watching big brother. LOL @ what they did to s...</td>\n",
       "      <td>[watch, big, brother, lol, sree, still, done, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2053389604</td>\n",
       "      <td>Sat Jun 06 04:22:52 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>lorna_hughes</td>\n",
       "      <td>@cromwellswirral sounds good, will make sure I...</td>\n",
       "      <td>[sound, good, make, sure, call, next, time, irbi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1993705920</td>\n",
       "      <td>Mon Jun 01 10:48:13 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>VisitBooneNC</td>\n",
       "      <td>@redmantw I love the Moses Cone Manor   It's g...</td>\n",
       "      <td>[love, mose, cone, manor, got, soul]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Polarity    Tweet_ID                          Date Query_username  \\\n",
       "0         4  1696135115  Mon May 04 07:40:55 PDT 2009       NO_QUERY   \n",
       "1         4  1692567464  Sun May 03 20:16:43 PDT 2009       NO_QUERY   \n",
       "2         4  2184090411  Mon Jun 15 15:24:29 PDT 2009       NO_QUERY   \n",
       "3         4  2053389604  Sat Jun 06 04:22:52 PDT 2009       NO_QUERY   \n",
       "4         4  1993705920  Mon Jun 01 10:48:13 PDT 2009       NO_QUERY   \n",
       "\n",
       "        Username                                         Tweet_text  \\\n",
       "0   mikesawriter                    @MmmBaileys @carli_chick Hello    \n",
       "1         CodyOW  @DSCarey tell me that didn't make your day hap...   \n",
       "2  chrisyoungken  watching big brother. LOL @ what they did to s...   \n",
       "3   lorna_hughes  @cromwellswirral sounds good, will make sure I...   \n",
       "4   VisitBooneNC  @redmantw I love the Moses Cone Manor   It's g...   \n",
       "\n",
       "                                         Tweet_clean  \n",
       "0                                     [chick, hello]  \n",
       "1          [tell, make, day, happier, though, lt, 3]  \n",
       "2  [watch, big, brother, lol, sree, still, done, ...  \n",
       "3  [sound, good, make, sure, call, next, time, irbi]  \n",
       "4               [love, mose, cone, manor, got, soul]  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_sub_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3. Separation en data d'entrainement et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seperation en data d'entrainement et de test\n",
    "\n",
    "Proportion_training = 0.7\n",
    "Data_train, Data_test = train_test_split(Data_sub_clean, test_size=(1-Proportion_training))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6999 3001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Tweet_ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Query_username</th>\n",
       "      <th>Username</th>\n",
       "      <th>Tweet_text</th>\n",
       "      <th>Tweet_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4579</th>\n",
       "      <td>4</td>\n",
       "      <td>2044147290</td>\n",
       "      <td>Fri Jun 05 08:56:20 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Winstonita</td>\n",
       "      <td>#followfriday @TonyLettws @Whatever-ista @reed...</td>\n",
       "      <td>[followfriday, ista, love]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6874</th>\n",
       "      <td>0</td>\n",
       "      <td>2198659794</td>\n",
       "      <td>Tue Jun 16 16:23:20 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>CBeSOS</td>\n",
       "      <td>@MissAliH everyones gones to bed so i'm offici...</td>\n",
       "      <td>[everyon, gone, bed, offici, sat, tod, livingr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7828</th>\n",
       "      <td>0</td>\n",
       "      <td>1994201994</td>\n",
       "      <td>Mon Jun 01 11:34:14 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>crossfitchat</td>\n",
       "      <td>Meeting ran over so I couldn't make Crossfit. ...</td>\n",
       "      <td>[meet, ran, make, crossfit, guess, miss, mke, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7112</th>\n",
       "      <td>0</td>\n",
       "      <td>2008020472</td>\n",
       "      <td>Tue Jun 02 13:30:09 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>keren4562</td>\n",
       "      <td>@Dannymcfly Danny why McFLY are'nt coming to i...</td>\n",
       "      <td>[danni, mcfli, nt, come, israel, hate, us, plz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7695</th>\n",
       "      <td>0</td>\n",
       "      <td>2011565617</td>\n",
       "      <td>Tue Jun 02 19:13:09 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Eminemdrdre00</td>\n",
       "      <td>@EndlessDennis Well she wont be in a match  *L...</td>\n",
       "      <td>[well, wont, match, layla, candic, michel, amp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Polarity    Tweet_ID                          Date Query_username  \\\n",
       "4579         4  2044147290  Fri Jun 05 08:56:20 PDT 2009       NO_QUERY   \n",
       "6874         0  2198659794  Tue Jun 16 16:23:20 PDT 2009       NO_QUERY   \n",
       "7828         0  1994201994  Mon Jun 01 11:34:14 PDT 2009       NO_QUERY   \n",
       "7112         0  2008020472  Tue Jun 02 13:30:09 PDT 2009       NO_QUERY   \n",
       "7695         0  2011565617  Tue Jun 02 19:13:09 PDT 2009       NO_QUERY   \n",
       "\n",
       "           Username                                         Tweet_text  \\\n",
       "4579     Winstonita  #followfriday @TonyLettws @Whatever-ista @reed...   \n",
       "6874         CBeSOS  @MissAliH everyones gones to bed so i'm offici...   \n",
       "7828   crossfitchat  Meeting ran over so I couldn't make Crossfit. ...   \n",
       "7112      keren4562  @Dannymcfly Danny why McFLY are'nt coming to i...   \n",
       "7695  Eminemdrdre00  @EndlessDennis Well she wont be in a match  *L...   \n",
       "\n",
       "                                            Tweet_clean  \n",
       "4579                         [followfriday, ista, love]  \n",
       "6874  [everyon, gone, bed, offici, sat, tod, livingr...  \n",
       "7828  [meet, ran, make, crossfit, guess, miss, mke, ...  \n",
       "7112  [danni, mcfli, nt, come, israel, hate, us, plz...  \n",
       "7695  [well, wont, match, layla, candic, michel, amp...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(Data_train),len(Data_test))\n",
    "Data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_train.reset_index(inplace=True)\n",
    "del Data_train['index']\n",
    "\n",
    "Data_test.reset_index(inplace=True)\n",
    "del Data_test['index']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.4. Creation de la liste de features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = []\n",
    "\n",
    "for t in Data_sub_clean[\"Tweet_clean\"]:\n",
    "    for w in t:\n",
    "        all_words.append(w)\n",
    "\n",
    "freq_all_words = nltk.FreqDist(all_words)\n",
    "\n",
    "\n",
    "list_features = [freq_all_words.most_common(200)[i][0] for i in range(200)] #la liste des features \n",
    "    #reprend les 3000 mots les plus fréquents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.5. Transformation des tweets en dictionnaires indiquant la présence de features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fonction qui permettra de transformer les tweets en dictionnaires indiquant la présence des features\n",
    "\n",
    "def find_features(document):\n",
    "    words = set(document)\n",
    "    features = {}\n",
    "    for w in list_features:\n",
    "        features[w] = (w in words)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definition du training set\n",
    "\n",
    "training_set = [(find_features(Data_train[\"Tweet_clean\"][index]),Data_train[\"Polarity\"][index]) for index in range(len(Data_train[\"Tweet_clean\"]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6999"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Définition du testing set\n",
    "\n",
    "testing_set = [(find_features(Data_test[\"Tweet_clean\"][index]),Data_test[\"Polarity\"][index]) for index in range(len(Data_test[\"Tweet_clean\"]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3001"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testing_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Data à analyser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importation\n",
    "\n",
    "dfDonaldTrump = pd.read_csv('hashtag_donaldtrump.csv', lineterminator='\\n', parse_dates=True)\n",
    "dfJoeBiden = pd.read_csv('hashtag_joebiden.csv', lineterminator='\\n', parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélection de la colonne des tweets\n",
    "tweets_biden = dfJoeBiden['tweet']\n",
    "tweets_trump = dfDonaldTrump['tweet']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1. Nettoyage des datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'une méthode pour supprimer les tweets présents dans les deux datasets\n",
    "def cleanList(listTweet, listHashtag) :\n",
    "    cleanedList = [] \n",
    "    for tweet in listTweet:\n",
    "        if not any(hashtag.upper() in tweet.upper() for hashtag in listHashtag):\n",
    "            cleanedList.append(tweet)\n",
    "    return cleanedList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanedTweetsTrump = cleanList(tweets_trump,['#JoeBiden', '#Biden'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanedTweetsBiden = cleanList(tweets_biden,['#DonaldTrump', '#Trump'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'une méthode pour ne garder que les tweets en anglais\n",
    "def getOnlyEnglishTweets(listTweet) :\n",
    "    onlyEnglishTweetsList = [] \n",
    "    for tweet in listTweet:\n",
    "        try:\n",
    "            if detect(tweet) == 'en' :\n",
    "                onlyEnglishTweetsList.append(tweet)\n",
    "        except:\n",
    "            pass\n",
    "    return onlyEnglishTweetsList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "englishTweetsTrump = getOnlyEnglishTweets(cleanedTweetsTrump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "englishTweetsBiden = getOnlyEnglishTweets(cleanedTweetsBiden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for prepro they need to be in a dataset\n",
    "\n",
    "dfDT_small = pd.DataFrame({\"tweet\":englishTweetsTrump})\n",
    "dfJB_small = pd.DataFrame({\"tweet\":englishTweetsBiden})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#Trump: As a student I used to hear for years,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2 hours since last tweet from #Trump! Maybe he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You get a tie! And you get a tie! #Trump ‘s ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@CLady62 Her 15 minutes were over long time ag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@richardmarx Glad u got out of the house! DICK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386334</th>\n",
       "      <td>@SenateGOP Any Senators big enough to tell #Tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386335</th>\n",
       "      <td>Congrats to all the idiots in Michigan for F’i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386336</th>\n",
       "      <td>@ewarren Maybe, just maybe, after his lawsuits...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386337</th>\n",
       "      <td>#democrats #election #politics #resistance #pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386338</th>\n",
       "      <td>@KBarnsey @KamalaHarris Hope you don’t mind if...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>386339 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    tweet\n",
       "0       #Trump: As a student I used to hear for years,...\n",
       "1       2 hours since last tweet from #Trump! Maybe he...\n",
       "2       You get a tie! And you get a tie! #Trump ‘s ra...\n",
       "3       @CLady62 Her 15 minutes were over long time ag...\n",
       "4       @richardmarx Glad u got out of the house! DICK...\n",
       "...                                                   ...\n",
       "386334  @SenateGOP Any Senators big enough to tell #Tr...\n",
       "386335  Congrats to all the idiots in Michigan for F’i...\n",
       "386336  @ewarren Maybe, just maybe, after his lawsuits...\n",
       "386337  #democrats #election #politics #resistance #pr...\n",
       "386338  @KBarnsey @KamalaHarris Hope you don’t mind if...\n",
       "\n",
       "[386339 rows x 1 columns]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfDT_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDT_clean = prepro(dfDT_small,'tweet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfJB_clean = prepro(dfJB_small,'tweet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>Tweet_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#Trump: As a student I used to hear for years,...</td>\n",
       "      <td>[trump, student, use, hear, year, ten, year, h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2 hours since last tweet from #Trump! Maybe he...</td>\n",
       "      <td>[2, hour, sinc, last, tweet, trump, mayb, busi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You get a tie! And you get a tie! #Trump ‘s ra...</td>\n",
       "      <td>[get, tie, get, tie, trump, ralli, iowa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@CLady62 Her 15 minutes were over long time ag...</td>\n",
       "      <td>[15, minut, long, time, ago, omarosa, never, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@richardmarx Glad u got out of the house! DICK...</td>\n",
       "      <td>[glad, u, got, hous, dick, trump, 2020]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  \\\n",
       "0  #Trump: As a student I used to hear for years,...   \n",
       "1  2 hours since last tweet from #Trump! Maybe he...   \n",
       "2  You get a tie! And you get a tie! #Trump ‘s ra...   \n",
       "3  @CLady62 Her 15 minutes were over long time ag...   \n",
       "4  @richardmarx Glad u got out of the house! DICK...   \n",
       "\n",
       "                                         Tweet_clean  \n",
       "0  [trump, student, use, hear, year, ten, year, h...  \n",
       "1  [2, hour, sinc, last, tweet, trump, mayb, busi...  \n",
       "2           [get, tie, get, tie, trump, ralli, iowa]  \n",
       "3  [15, minut, long, time, ago, omarosa, never, r...  \n",
       "4            [glad, u, got, hous, dick, trump, 2020]  "
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfDT_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2. Transformations des tweets en dictionnaires indiquant la présence des features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweet_set_DT = [(find_features(dfDT_clean[\"Tweet_clean\"][index])) for index in range(len(dfDT_clean[\"Tweet_clean\"]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_set_DT[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_set_JB = [(find_features(dfJB_clean[\"Tweet_clean\"][index])) for index in range(len(dfJB_clean[\"Tweet_clean\"]))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the algo\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the algo\n",
    "test = nltk.classify.accuracy(classifier, testing_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'accurancy est de 68.71042985671443 %\n"
     ]
    }
   ],
   "source": [
    "print(\"L'accuracy est de {} %\".format(test*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                     ugh = True                0 : 4      =     35.2 : 1.0\n",
      "                     sad = True                0 : 4      =     32.3 : 1.0\n",
      "                    lost = True                0 : 4      =     20.3 : 1.0\n",
      "                    damn = True                0 : 4      =      7.9 : 1.0\n",
      "                    sick = True                0 : 4      =      7.3 : 1.0\n",
      "                    suck = True                0 : 4      =      6.9 : 1.0\n",
      "                    hate = True                0 : 4      =      6.5 : 1.0\n",
      "                    miss = True                0 : 4      =      5.4 : 1.0\n",
      "                   thank = True                4 : 0      =      5.1 : 1.0\n",
      "                   enjoy = True                4 : 0      =      4.4 : 1.0\n",
      "                    hurt = True                0 : 4      =      4.0 : 1.0\n",
      "                  awesom = True                4 : 0      =      3.9 : 1.0\n",
      "                birthday = True                4 : 0      =      3.8 : 1.0\n",
      "                    rain = True                0 : 4      =      3.7 : 1.0\n",
      "                   phone = True                0 : 4      =      3.5 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the algo sur le set de Donald Trump\n",
    "Class_DT = [classifier.classify(tweet_set_DT[i]) for i in range(len(tweet_set_DT))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the algo sur le set de Joe Biden\n",
    "Class_JB = [classifier.classify(tweet_set_JB[i]) for i in range(len(tweet_set_JB))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les tweets concernant Donald Trump sont positifs dans 64.20734122105198% des cas\n"
     ]
    }
   ],
   "source": [
    "print(\"Les tweets concernant Donald Trump sont positifs dans {}% des cas\".format(Class_DT.count(4)/(len(Class_DT))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les tweets concernant Joe Bieden sont positifs dans 64.14571266270809% des cas\n"
     ]
    }
   ],
   "source": [
    "print(\"Les tweets concernant Joe Bieden sont positifs dans {}% des cas\".format(Class_JB.count(4)/(len(Class_JB))*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
