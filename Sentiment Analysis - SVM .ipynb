{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.TRAINING "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Gathering data's "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/constancevandendorpe/Desktop/UCLM2Q1/LBIRTI2101B - Data Science in bioscience enginerring - Partim B /datasets')\n",
    "Data_entrainement = pd.read_csv('./training.1600000.processed.noemoticon.csv',header = None,encoding = 'ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Tweet_ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Query_username</th>\n",
       "      <th>Username</th>\n",
       "      <th>Tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1599995</td>\n",
       "      <td>4</td>\n",
       "      <td>2193601966</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>AmandaMarie1028</td>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1599996</td>\n",
       "      <td>4</td>\n",
       "      <td>2193601969</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>TheWDBoards</td>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1599997</td>\n",
       "      <td>4</td>\n",
       "      <td>2193601991</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>bpbabe</td>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1599998</td>\n",
       "      <td>4</td>\n",
       "      <td>2193602064</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>tinydiamondz</td>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1599999</td>\n",
       "      <td>4</td>\n",
       "      <td>2193602129</td>\n",
       "      <td>Tue Jun 16 08:40:50 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>RyanTrevMorris</td>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Polarity    Tweet_ID                          Date Query_username  \\\n",
       "0               0  1467810369  Mon Apr 06 22:19:45 PDT 2009       NO_QUERY   \n",
       "1               0  1467810672  Mon Apr 06 22:19:49 PDT 2009       NO_QUERY   \n",
       "2               0  1467810917  Mon Apr 06 22:19:53 PDT 2009       NO_QUERY   \n",
       "3               0  1467811184  Mon Apr 06 22:19:57 PDT 2009       NO_QUERY   \n",
       "4               0  1467811193  Mon Apr 06 22:19:57 PDT 2009       NO_QUERY   \n",
       "...           ...         ...                           ...            ...   \n",
       "1599995         4  2193601966  Tue Jun 16 08:40:49 PDT 2009       NO_QUERY   \n",
       "1599996         4  2193601969  Tue Jun 16 08:40:49 PDT 2009       NO_QUERY   \n",
       "1599997         4  2193601991  Tue Jun 16 08:40:49 PDT 2009       NO_QUERY   \n",
       "1599998         4  2193602064  Tue Jun 16 08:40:49 PDT 2009       NO_QUERY   \n",
       "1599999         4  2193602129  Tue Jun 16 08:40:50 PDT 2009       NO_QUERY   \n",
       "\n",
       "                Username                                         Tweet_text  \n",
       "0        _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1          scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2               mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3                ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4                 Karoli  @nationwideclass no, it's not behaving at all....  \n",
       "...                  ...                                                ...  \n",
       "1599995  AmandaMarie1028  Just woke up. Having no school is the best fee...  \n",
       "1599996      TheWDBoards  TheWDB.com - Very cool to hear old Walt interv...  \n",
       "1599997           bpbabe  Are you ready for your MoJo Makeover? Ask me f...  \n",
       "1599998     tinydiamondz  Happy 38th Birthday to my boo of alll time!!! ...  \n",
       "1599999   RyanTrevMorris  happy #charitytuesday @theNSPCC @SparksCharity...  \n",
       "\n",
       "[1600000 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Affichage du dataset d'entrainement \n",
    "Data_entrainement.columns = ['Polarity', 'Tweet_ID','Date','Query_username','Username','Tweet_text']\n",
    "Data_entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On a 1600000 de tweets au total. On va donc seulement en prendre 10000 .\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Tweet_ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Query_username</th>\n",
       "      <th>Username</th>\n",
       "      <th>Tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>314483</td>\n",
       "      <td>0</td>\n",
       "      <td>2001982499</td>\n",
       "      <td>Tue Jun 02 02:44:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>anneAAM</td>\n",
       "      <td>@vintagepolka but he doesnt eat icecream  @Kyl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>437477</td>\n",
       "      <td>0</td>\n",
       "      <td>2065932810</td>\n",
       "      <td>Sun Jun 07 09:34:17 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>iolanda76</td>\n",
       "      <td>Great. Forgott my keys at my parents. Now drov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>786715</td>\n",
       "      <td>0</td>\n",
       "      <td>2324720501</td>\n",
       "      <td>Thu Jun 25 03:52:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>gilltaylorphoto</td>\n",
       "      <td>bookkeeping day today - needs must</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>711994</td>\n",
       "      <td>0</td>\n",
       "      <td>2258393521</td>\n",
       "      <td>Sat Jun 20 15:51:16 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Jupiter264</td>\n",
       "      <td>About to head to the park.. extra bored! i wan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>738826</td>\n",
       "      <td>0</td>\n",
       "      <td>2265567903</td>\n",
       "      <td>Sun Jun 21 06:51:56 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>MichelBrooks</td>\n",
       "      <td>Happy Fathers Day...first one without my dad o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Polarity    Tweet_ID                          Date Query_username  \\\n",
       "314483         0  2001982499  Tue Jun 02 02:44:49 PDT 2009       NO_QUERY   \n",
       "437477         0  2065932810  Sun Jun 07 09:34:17 PDT 2009       NO_QUERY   \n",
       "786715         0  2324720501  Thu Jun 25 03:52:53 PDT 2009       NO_QUERY   \n",
       "711994         0  2258393521  Sat Jun 20 15:51:16 PDT 2009       NO_QUERY   \n",
       "738826         0  2265567903  Sun Jun 21 06:51:56 PDT 2009       NO_QUERY   \n",
       "\n",
       "               Username                                         Tweet_text  \n",
       "314483          anneAAM  @vintagepolka but he doesnt eat icecream  @Kyl...  \n",
       "437477        iolanda76  Great. Forgott my keys at my parents. Now drov...  \n",
       "786715  gilltaylorphoto                bookkeeping day today - needs must   \n",
       "711994       Jupiter264  About to head to the park.. extra bored! i wan...  \n",
       "738826     MichelBrooks  Happy Fathers Day...first one without my dad o...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Besoin d'entrainer sur beaucoup moins de tweets (j'en prends que 2n ici, n positifs et n négatifs)! \n",
    "n = 5000\n",
    "number_tweets = list(Data_entrainement.shape)[0]\n",
    "print('On a',number_tweets, 'de tweets au total. On va donc seulement en prendre',2*n,'.')\n",
    "\n",
    "Datapos = Data_entrainement[Data_entrainement['Polarity']==0]\n",
    "Dataneg = Data_entrainement[Data_entrainement['Polarity']==4]\n",
    "\n",
    "Data_sub = pd.concat([Datapos.sample(n),Dataneg.sample(n)], axis=0)\n",
    "Data_sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Dividing between training and testing data's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On va diviser ce dataset en données d'entrainement et données test. J'ai choisi au hasard une proportion 70/30. \n",
    "Proportion_training = 0.7\n",
    "Data_train, Data_test = train_test_split(Data_sub, test_size=(1-Proportion_training))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Vectorizing the data's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Pas de parametres particuliers à inclure (https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "train_vectors = vectorizer.fit_transform(Data_train['Tweet_text'])\n",
    "test_vectors = vectorizer.transform(Data_test['Tweet_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpreting the output of vectorizer : \n",
    "\n",
    "Assume general form: (A,B) C \n",
    "\n",
    "A: Document index B: Specific word-vector index C: TFIDF score for word B in document A\n",
    "\n",
    "This is a sparse matrix. It indicates the tfidf score for all non-zero values in the word vector for each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ce qui sort du vectorizer est une matrice de taille (6999, 14572) , où chaque ligne correspond à un document et chaque colonne correspond à un mot.\n",
      " Chaque case de la matrice est un score TFIDF. La matrice contient donc plein de 0, c est pour cela qu on imprime que les couples (document,mot) pour lesquels il y a un score.\n",
      "\n",
      "  (0, 13055)\t0.21058774703341437\n",
      "  (0, 9356)\t0.2848471516276849\n",
      "  (0, 14431)\t0.1165173289191115\n",
      "  (0, 2387)\t0.3106516990414836\n",
      "  (0, 2280)\t0.15721493958311503\n",
      "  (0, 6167)\t0.1848282567085211\n",
      "  (0, 11263)\t0.18544147600400607\n",
      "  (0, 13042)\t0.19843969543601528\n",
      "  (0, 11553)\t0.35522668900321547\n",
      "  (0, 4865)\t0.12574101804227775\n",
      "  (0, 7412)\t0.27438601799798884\n",
      "  (0, 1752)\t0.3154306166689303\n",
      "  (0, 5903)\t0.3716779915329416\n",
      "  (0, 5981)\t0.19677203997649464\n",
      "  (0, 7630)\t0.3716779915329416\n",
      "  (1, 13321)\t0.22397588185553235\n",
      "  (1, 8787)\t0.09800026296172397\n",
      "  (1, 9261)\t0.1182773295254995\n",
      "  (1, 10343)\t0.306374007371873\n",
      "  (1, 11383)\t0.27321995504283214\n",
      "  (1, 11796)\t0.12325195416415251\n",
      "  (1, 908)\t0.100388758904122\n",
      "  (1, 12675)\t0.22216636000504028\n",
      "  (1, 14054)\t0.16537254069624557\n",
      "  (1, 12942)\t0.160243749461138\n",
      "  :\t:\n",
      "  (6997, 12741)\t0.7071067811865475\n",
      "  (6997, 2099)\t0.7071067811865475\n",
      "  (6998, 5230)\t0.3361632447504484\n",
      "  (6998, 11211)\t0.31072684486435903\n",
      "  (6998, 4985)\t0.29584750477764893\n",
      "  (6998, 13271)\t0.27710175322214786\n",
      "  (6998, 13814)\t0.20622077383997156\n",
      "  (6998, 5194)\t0.1948745015163622\n",
      "  (6998, 11065)\t0.2089812453200017\n",
      "  (6998, 14361)\t0.192603861807758\n",
      "  (6998, 4290)\t0.24497470500547022\n",
      "  (6998, 7707)\t0.22110011392668172\n",
      "  (6998, 12904)\t0.3025381531082372\n",
      "  (6998, 13882)\t0.15810844554782302\n",
      "  (6998, 10500)\t0.1813201056286952\n",
      "  (6998, 12342)\t0.2290899056404658\n",
      "  (6998, 6431)\t0.10323330620690441\n",
      "  (6998, 1190)\t0.13899187032881793\n",
      "  (6998, 7673)\t0.15404189429520423\n",
      "  (6998, 7532)\t0.15132235641448102\n",
      "  (6998, 13010)\t0.0830383873602199\n",
      "  (6998, 8176)\t0.12335412733301941\n",
      "  (6998, 7951)\t0.19223871483511124\n",
      "  (6998, 12754)\t0.08543147549061864\n",
      "  (6998, 14431)\t0.10538381139425702\n"
     ]
    }
   ],
   "source": [
    "print('Ce qui sort du vectorizer est une matrice de taille',train_vectors.shape,', où chaque ligne correspond à un document et chaque colonne correspond à un mot.\\n Chaque case de la matrice est un score TFIDF. La matrice contient donc plein de 0, c est pour cela qu on imprime que les couples (document,mot) pour lesquels il y a un score.\\n')\n",
    "print(train_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Creating a Linear SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_linear est une liste qui contient des 0 et des 4.\n",
      "La précision pour les tweets positifs est de 0.7462589459986988 \n",
      " La précision pour les tweets négatifs est de 0.7418032786885246\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Perform classification with SVM, kernel=linear\n",
    "\n",
    "# Le classifier sera SVC : take as input two arrays: an array X of shape (n_samples, n_features) \n",
    "# holding the training samples, and an array y of class labels (strings or integers), of shape (n_samples)\n",
    "\n",
    "# Training \n",
    "classifier_linear = svm.SVC(kernel='linear') \n",
    "classifier_linear.fit(train_vectors, Data_train['Polarity']) #fit pour définir le modèle \n",
    "\n",
    "# Testing \n",
    "prediction_linear = classifier_linear.predict(test_vectors) #predict pour prédire \n",
    "\n",
    "# results\n",
    "report = classification_report(Data_test['Polarity'], prediction_linear, output_dict=True)\n",
    "#print('positive: ', report['0'])\n",
    "#print('negative: ', report['4'])\n",
    "print('prediction_linear est une liste qui contient des 0 et des 4.')\n",
    "print('La précision pour les tweets positifs est de',report['0']['precision'],'\\n La précision pour les tweets négatifs est de',report['4']['precision'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. US ELECTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Gathering datas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/constancevandendorpe/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "Data_trump = pd.read_csv('./hashtag_donaldtrump.csv',delimiter=',',engine = 'python')\n",
    "Data_biden = pd.read_csv('./hashtag_joebiden.csv',delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trumps dataset is 331899 long.\n",
      "Bidens dataset is 82348 long.\n"
     ]
    }
   ],
   "source": [
    "# Quelle est la taille de ces datasets ? \n",
    "print('Trumps dataset is', list(Data_trump.shape)[0], 'long.')\n",
    "print('Bidens dataset is', list(Data_biden.shape)[0], 'long.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On ne va garder que les colonnes sur les tweets et leur id\n",
    "# Besoin d'entrainer sur beaucoup moins de tweets (j'en prends que 10 000 ici, 5000 pour Biden et 5000 pour Trump)! \n",
    "\n",
    "Data_biden_small = Data_biden[['tweet_id','tweet']].sample(n)\n",
    "Data_trump_small = Data_trump[['tweet_id','tweet']].sample(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Preprocessing and vectorizing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A propos du prepro : Il y a un preprocesssing plus important à faire sur les datasets trump et biden que sur le dataset d'entrainement. \n",
    "- Les étapes de text-cleaning & lowercase sont faites ici. \n",
    "- L'étape de tokenization est faite avec scikitlearn. \n",
    "- Les étapes de removal des stop words et stemming ne sont pas réalisées. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepro_SVM(text,i):\n",
    "    clean=text[i].astype(str).str.replace(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \")\n",
    "    #lowercase=clean.str.lower()\n",
    "    #words=lowercase.apply(word_tokenize)\n",
    "    #stop_words = stopwords.words('english') \n",
    "    #filtered_words = words.apply(lambda x:[word for word in x if word not in stop_words])\n",
    "    #porter = PorterStemmer()\n",
    "    #text['Tweet_clean']=filtered_words.apply(lambda x:[porter.stem(word) for word in x])\n",
    "    text['Tweet_clean']=clean.str.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_biden_clean=prepro_SVM(Data_biden_small,'tweet')\n",
    "Data_trump_clean=prepro_SVM(Data_trump_small,'tweet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorization en utilisant le même vectorizer que pour le dataset d'entrainement, \n",
    "# après avoir un peu nettoyé les données. \n",
    "vectors_trump = vectorizer.transform(Data_trump_clean['Tweet_clean'])\n",
    "vectors_biden = vectorizer.transform(Data_biden_clean['Tweet_clean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Predicting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On utilise le classifier généré pendant la phase d'entrainement\n",
    "prediction_trump = classifier_linear.predict(vectors_trump)\n",
    "prediction_biden = classifier_linear.predict(vectors_biden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trump has a positive percentage of : 60.72 %\n",
      "Biden has a positive percentage of : 65.12 %\n"
     ]
    }
   ],
   "source": [
    "trump_list = list(prediction_trump)\n",
    "biden_list = list(prediction_biden)\n",
    "print('Trump has a positive percentage of :', trump_list.count(4)/len(trump_list)*100,'%')\n",
    "print('Biden has a positive percentage of :', biden_list.count(4)/len(biden_list)*100,'%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
