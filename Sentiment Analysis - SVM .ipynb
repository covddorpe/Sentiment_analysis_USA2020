{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.TRAINING "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Gathering data's "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/constancevandendorpe/Desktop/UCLM2Q1/LBIRTI2101B - Data Science in bioscience enginerring - Partim B /datasets')\n",
    "Data_entrainement = pd.read_csv('./training.1600000.processed.noemoticon.csv',header = None,encoding = 'ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Tweet_ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Query_username</th>\n",
       "      <th>Username</th>\n",
       "      <th>Tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1599995</td>\n",
       "      <td>4</td>\n",
       "      <td>2193601966</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>AmandaMarie1028</td>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1599996</td>\n",
       "      <td>4</td>\n",
       "      <td>2193601969</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>TheWDBoards</td>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1599997</td>\n",
       "      <td>4</td>\n",
       "      <td>2193601991</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>bpbabe</td>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1599998</td>\n",
       "      <td>4</td>\n",
       "      <td>2193602064</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>tinydiamondz</td>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1599999</td>\n",
       "      <td>4</td>\n",
       "      <td>2193602129</td>\n",
       "      <td>Tue Jun 16 08:40:50 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>RyanTrevMorris</td>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Polarity    Tweet_ID                          Date Query_username  \\\n",
       "0               0  1467810369  Mon Apr 06 22:19:45 PDT 2009       NO_QUERY   \n",
       "1               0  1467810672  Mon Apr 06 22:19:49 PDT 2009       NO_QUERY   \n",
       "2               0  1467810917  Mon Apr 06 22:19:53 PDT 2009       NO_QUERY   \n",
       "3               0  1467811184  Mon Apr 06 22:19:57 PDT 2009       NO_QUERY   \n",
       "4               0  1467811193  Mon Apr 06 22:19:57 PDT 2009       NO_QUERY   \n",
       "...           ...         ...                           ...            ...   \n",
       "1599995         4  2193601966  Tue Jun 16 08:40:49 PDT 2009       NO_QUERY   \n",
       "1599996         4  2193601969  Tue Jun 16 08:40:49 PDT 2009       NO_QUERY   \n",
       "1599997         4  2193601991  Tue Jun 16 08:40:49 PDT 2009       NO_QUERY   \n",
       "1599998         4  2193602064  Tue Jun 16 08:40:49 PDT 2009       NO_QUERY   \n",
       "1599999         4  2193602129  Tue Jun 16 08:40:50 PDT 2009       NO_QUERY   \n",
       "\n",
       "                Username                                         Tweet_text  \n",
       "0        _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1          scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2               mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3                ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4                 Karoli  @nationwideclass no, it's not behaving at all....  \n",
       "...                  ...                                                ...  \n",
       "1599995  AmandaMarie1028  Just woke up. Having no school is the best fee...  \n",
       "1599996      TheWDBoards  TheWDB.com - Very cool to hear old Walt interv...  \n",
       "1599997           bpbabe  Are you ready for your MoJo Makeover? Ask me f...  \n",
       "1599998     tinydiamondz  Happy 38th Birthday to my boo of alll time!!! ...  \n",
       "1599999   RyanTrevMorris  happy #charitytuesday @theNSPCC @SparksCharity...  \n",
       "\n",
       "[1600000 rows x 6 columns]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Affichage du dataset d'entrainement \n",
    "Data_entrainement.columns = ['Polarity', 'Tweet_ID','Date','Query_username','Username','Tweet_text']\n",
    "Data_entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On a 1600000 de tweets au total. On va donc seulement en prendre 10000 .\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Tweet_ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Query_username</th>\n",
       "      <th>Username</th>\n",
       "      <th>Tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>479620</td>\n",
       "      <td>0</td>\n",
       "      <td>2178951876</td>\n",
       "      <td>Mon Jun 15 08:26:16 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>becksdavis</td>\n",
       "      <td>I want to go to @SlowsBBQ! Everyone keeps talk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>301457</td>\n",
       "      <td>0</td>\n",
       "      <td>1998654666</td>\n",
       "      <td>Mon Jun 01 18:54:33 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>fentonslee</td>\n",
       "      <td>@fyreflye17 @naomitripi and spouse seems to th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770822</td>\n",
       "      <td>0</td>\n",
       "      <td>2302122925</td>\n",
       "      <td>Tue Jun 23 16:22:16 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mike_nelson</td>\n",
       "      <td>@ChristineMarieN Wow you guys have a great loo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>623374</td>\n",
       "      <td>0</td>\n",
       "      <td>2229530857</td>\n",
       "      <td>Thu Jun 18 15:51:13 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>twins160</td>\n",
       "      <td>I hate how people grow apart   But SUCH great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>597075</td>\n",
       "      <td>0</td>\n",
       "      <td>2219177147</td>\n",
       "      <td>Wed Jun 17 23:57:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>YGee</td>\n",
       "      <td>RIP Lou</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Polarity    Tweet_ID                          Date Query_username  \\\n",
       "479620         0  2178951876  Mon Jun 15 08:26:16 PDT 2009       NO_QUERY   \n",
       "301457         0  1998654666  Mon Jun 01 18:54:33 PDT 2009       NO_QUERY   \n",
       "770822         0  2302122925  Tue Jun 23 16:22:16 PDT 2009       NO_QUERY   \n",
       "623374         0  2229530857  Thu Jun 18 15:51:13 PDT 2009       NO_QUERY   \n",
       "597075         0  2219177147  Wed Jun 17 23:57:57 PDT 2009       NO_QUERY   \n",
       "\n",
       "           Username                                         Tweet_text  \n",
       "479620   becksdavis  I want to go to @SlowsBBQ! Everyone keeps talk...  \n",
       "301457   fentonslee  @fyreflye17 @naomitripi and spouse seems to th...  \n",
       "770822  mike_nelson  @ChristineMarieN Wow you guys have a great loo...  \n",
       "623374     twins160  I hate how people grow apart   But SUCH great ...  \n",
       "597075         YGee                                           RIP Lou   "
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Besoin d'entrainer sur beaucoup moins de tweets (j'en prends que 2n ici, n positifs et n négatifs)! \n",
    "n = 5000\n",
    "number_tweets = list(Data_entrainement.shape)[0]\n",
    "print('On a',number_tweets, 'de tweets au total. On va donc seulement en prendre',2*n,'.')\n",
    "\n",
    "Datapos = Data_entrainement[Data_entrainement['Polarity']==0]\n",
    "Dataneg = Data_entrainement[Data_entrainement['Polarity']==4]\n",
    "\n",
    "Data_sub = pd.concat([Datapos.sample(n),Dataneg.sample(n)], axis=0)\n",
    "Data_sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Dividing between training and testing data's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On va diviser ce dataset en données d'entrainement et données test. J'ai choisi au hasard une proportion 70/30. \n",
    "Proportion_training = 0.7\n",
    "Data_train, Data_test = train_test_split(Data_sub, test_size=(1-Proportion_training))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Vectorizing the data's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Pas de parametres particuliers à inclure (https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "train_vectors = vectorizer.fit_transform(Data_train['Tweet_text'])\n",
    "test_vectors = vectorizer.transform(Data_test['Tweet_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpreting the output of vectorizer : \n",
    "\n",
    "Assume general form: (A,B) C \n",
    "\n",
    "A: Document index B: Specific word-vector index C: TFIDF score for word B in document A\n",
    "\n",
    "This is a sparse matrix. It indicates the tfidf score for all non-zero values in the word vector for each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ce qui sort du vectorizer est une matrice de taille (6999, 14646) , où chaque ligne correspond à un document et chaque colonne correspond à un mot.\n",
      " Chaque case de la matrice est un score TFIDF. La matrice contient donc plein de 0, c est pour cela qu on imprime que les couples (document,mot) pour lesquels il y a un score.\n",
      "\n",
      "  (0, 6488)\t0.11395623588725694\n",
      "  (0, 6417)\t0.2419592188529535\n",
      "  (0, 4015)\t0.3283018952532073\n",
      "  (0, 6920)\t0.14394211906678459\n",
      "  (0, 11844)\t0.24278192593183476\n",
      "  (0, 8154)\t0.22884313640951345\n",
      "  (0, 9375)\t0.20091253618342947\n",
      "  (0, 5820)\t0.3283018952532073\n",
      "  (0, 12766)\t0.09402055181811271\n",
      "  (0, 14158)\t0.1476257691682406\n",
      "  (0, 9432)\t0.16045371869732852\n",
      "  (0, 2181)\t0.31658672887706185\n",
      "  (0, 13186)\t0.35652866125989663\n",
      "  (0, 11838)\t0.1818099318139314\n",
      "  (0, 12406)\t0.22884313640951345\n",
      "  (0, 875)\t0.17946163606265214\n",
      "  (0, 6596)\t0.3730402608904405\n",
      "  (1, 9811)\t0.3824548199262196\n",
      "  (1, 913)\t0.18854988605556103\n",
      "  (1, 3966)\t0.3245765486403304\n",
      "  (1, 1223)\t0.15151647823928938\n",
      "  (1, 10921)\t0.33015153068185105\n",
      "  (1, 7896)\t0.3196590659744638\n",
      "  (1, 9474)\t0.2804859825335665\n",
      "  (1, 4562)\t0.3196590659744638\n",
      "  :\t:\n",
      "  (6997, 12139)\t0.30470541757057606\n",
      "  (6997, 4417)\t0.30470541757057606\n",
      "  (6997, 10132)\t0.2912184715552218\n",
      "  (6997, 5256)\t0.27422692906926827\n",
      "  (6997, 7116)\t0.23768389655481836\n",
      "  (6997, 12182)\t0.2816493310714804\n",
      "  (6997, 4898)\t0.25859324457238475\n",
      "  (6997, 7920)\t0.19048103890479567\n",
      "  (6997, 6298)\t0.20321035517240535\n",
      "  (6997, 7642)\t0.18327393151604157\n",
      "  (6997, 5949)\t0.19830826823642753\n",
      "  (6997, 942)\t0.09319632400118817\n",
      "  (6997, 13040)\t0.13825964371125196\n",
      "  (6997, 4903)\t0.1023552184210098\n",
      "  (6997, 6488)\t0.1861626536391236\n",
      "  (6997, 12766)\t0.07679753234562507\n",
      "  (6997, 14158)\t0.12058315510292135\n",
      "  (6997, 11838)\t0.1485053411114574\n",
      "  (6998, 10297)\t0.5037772118392211\n",
      "  (6998, 1127)\t0.4814789011822813\n",
      "  (6998, 9466)\t0.46565799799311997\n",
      "  (6998, 12994)\t0.3694618001362975\n",
      "  (6998, 2885)\t0.24164979183677163\n",
      "  (6998, 6095)\t0.22449947949122515\n",
      "  (6998, 13040)\t0.2285881832166826\n"
     ]
    }
   ],
   "source": [
    "print('Ce qui sort du vectorizer est une matrice de taille',train_vectors.shape,', où chaque ligne correspond à un document et chaque colonne correspond à un mot.\\n Chaque case de la matrice est un score TFIDF. La matrice contient donc plein de 0, c est pour cela qu on imprime que les couples (document,mot) pour lesquels il y a un score.\\n')\n",
    "print(train_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Creating a Linear SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_linear est une liste qui contient des 0 et des 4.\n",
      "La précision pour les tweets positifs est de 0.7340894770006301 \n",
      " La précision pour les tweets négatifs est de 0.743988684582744\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Perform classification with SVM, kernel=linear\n",
    "\n",
    "# Le classifier sera SVC : take as input two arrays: an array X of shape (n_samples, n_features) \n",
    "# holding the training samples, and an array y of class labels (strings or integers), of shape (n_samples)\n",
    "\n",
    "# Training \n",
    "classifier_linear = svm.SVC(kernel='linear') \n",
    "classifier_linear.fit(train_vectors, Data_train['Polarity']) #fit pour définir le modèle \n",
    "\n",
    "# Testing \n",
    "prediction_linear = classifier_linear.predict(test_vectors) #predict pour prédire \n",
    "\n",
    "# results\n",
    "#report = classification_report(Data_test['Polarity'], prediction_linear, output_dict=True)\n",
    "#print('positive: ', report['0'])\n",
    "#print('negative: ', report['4'])\n",
    "print('prediction_linear est une liste qui contient des 0 et des 4.')\n",
    "print('La précision pour les tweets positifs est de',report['0']['precision'],'\\n La précision pour les tweets négatifs est de',report['4']['precision'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. US ELECTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Gathering datas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_trump = pd.read_csv('./hashtag_donaldtrump.csv',delimiter=',',engine = 'python')\n",
    "Data_biden = pd.read_csv('./hashtag_joebiden.csv',delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trumps dataset is 331899 long.\n",
      "Bidens dataset is 82348 long.\n"
     ]
    }
   ],
   "source": [
    "# Quelle est la taille de ces datasets ? \n",
    "print('Trumps dataset is', list(Data_trump.shape)[0], 'long.')\n",
    "print('Bidens dataset is', list(Data_biden.shape)[0], 'long.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On ne va garder que les colonnes sur les tweets et leur id\n",
    "# Besoin d'entrainer sur beaucoup moins de tweets (j'en prends que 10 000 ici, 5000 pour Biden et 5000 pour Trump)! \n",
    "\n",
    "Data_biden_small = Data_biden[['tweet_id','tweet']].sample(5000)\n",
    "Data_trump_small = Data_trump[['tweet_id','tweet']].sample(5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Preprocessing and vectorizing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A propos du prepro : Il y a un preprocesssing plus important à faire sur les datasets trump et biden que sur le dataset d'entrainement. \n",
    "- Les étapes de text-cleaning & lowercase sont faites ici. \n",
    "- L'étape de tokenization est faite avec scikitlearn. \n",
    "- Les étapes de removal des stop words et stemming ne sont pas réalisées. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepro_SVM(text,i):\n",
    "    clean=text[i].astype(str).str.replace(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \")\n",
    "    #lowercase=clean.str.lower()\n",
    "    #words=lowercase.apply(word_tokenize)\n",
    "    #stop_words = stopwords.words('english') \n",
    "    #filtered_words = words.apply(lambda x:[word for word in x if word not in stop_words])\n",
    "    #porter = PorterStemmer()\n",
    "    #text['Tweet_clean']=filtered_words.apply(lambda x:[porter.stem(word) for word in x])\n",
    "    text['Tweet_clean']=clean.str.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_biden_clean=prepro_SVM(Data_biden_small,'tweet')\n",
    "Data_trump_clean=prepro_SVM(Data_trump_small,'tweet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorization en utilisant le même vectorizer que pour le dataset d'entrainement, \n",
    "# après avoir un peu nettoyé les données. \n",
    "vectors_trump = vectorizer.transform(Data_trump_clean['Tweet_clean'])\n",
    "vectors_biden = vectorizer.transform(Data_biden_clean['Tweet_clean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Predicting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On utilise le classifier généré pendant la phase d'entrainement\n",
    "prediction_trump = classifier_linear.predict(vectors_trump)\n",
    "prediction_biden = classifier_linear.predict(vectors_biden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trump has a positive percentage of : 63.0 %\n",
      "Biden has a positive percentage of : 65.03999999999999 %\n"
     ]
    }
   ],
   "source": [
    "trump_list = list(prediction_trump)\n",
    "biden_list = list(prediction_biden)\n",
    "print('Trump has a positive percentage of :', trump_list.count(4)/len(trump_list)*100,'%')\n",
    "print('Biden has a positive percentage of :', biden_list.count(4)/len(biden_list)*100,'%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
